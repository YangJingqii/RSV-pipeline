{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "488446b3-9be7-4091-b457-84a484f34262",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'AO'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_699/1809339018.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;31m#             print(record.INFO)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m                 \u001b[0malt_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mINFO\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'AO'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m                 \u001b[0mref_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mINFO\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'RO'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                 \u001b[0mref\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'='\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'AO'"
     ]
    }
   ],
   "source": [
    "#05 统计bayes的每个样本reads数，写成A256G的形式，过滤，只过滤测序深度,不过滤频率。\n",
    "#统计每个样本的突变数量\n",
    "#dp>100并且在至少2个样本中出现过的才算。\n",
    "#变异类型是snp或者del或ins，这里也筛选了。\n",
    "#最终输出csv文件。\n",
    "\n",
    "import csv\n",
    "import os\n",
    "import vcf\n",
    "wenjianjia_list = os.listdir('/mnt/alamo01/users/yangjingqi/RSV_sra/yjq_sra_bioproject_rsv')\n",
    "for i in wenjianjia_list:\n",
    "    dirs = f'/mnt/alamo01/users/yangjingqi/RSV_sra/group/10change_lofreq/01filtered_csv_deep_sample/{i}'\n",
    "    if not os.path.exists(dirs):\n",
    "        os.makedirs(dirs)\n",
    "\n",
    "for p in os.listdir('/mnt/alamo01/users/yangjingqi/RSV_sra/group/10change_lofreq/vcf_pair'):\n",
    "    prj_path = f'/mnt/alamo01/users/yangjingqi/RSV_sra/group/10change_lofreq/vcf_pair/{p}'\n",
    "    \n",
    "    bayes_filenames=os.listdir(prj_path)\n",
    "    type_list= []\n",
    "    dict_mut_num = {}#在几个样本中出现过。形成列表，在列表中的才算真正的突变。\n",
    "    #找出突变在几个样本中出现\n",
    "    for i in bayes_filenames:\n",
    "        if i.endswith('vcf'):\n",
    "            i_1 = i.split('.')[0]\n",
    "            reads_pos_dict = {}\n",
    "            path1 = prj_path+'/'+i\n",
    "            vcf_reader = vcf.Reader(filename=path1)\n",
    "            for record in vcf_reader:\n",
    "    #             print(record)\n",
    "    #             print(record.INFO)\n",
    "\n",
    "                alt_count = record.INFO['AO']\n",
    "                ref_count = record.INFO['RO']\n",
    "                ref = str(record).split(',')[2].split('=')[1]\n",
    "                type0 = record.INFO['TYPE']\n",
    "                position = str(record).split(',')[1].split('=')[1]\n",
    "                dp = record.INFO['DP']\n",
    "                if type0 not in type_list:\n",
    "                    type_list.append(type0)\n",
    "                for i in range(0,len(record.INFO['TYPE'])):\n",
    "                    alt1 = str(record).split('=')[4].replace(')','').replace('[','').replace(']','').replace(' ','')\n",
    "                    alt2 = alt1.split(\",\")#转成列表,碱基\n",
    "                    type2 = record.INFO['TYPE'][i]\n",
    "                    info = f'{ref}_{position}_{alt2[i]}'\n",
    "                    alt_count1 = alt_count[i]\n",
    "                    af = record.INFO['AO'][i]/(record.INFO['AO'][i] + record.INFO['RO'])\n",
    "    #                 print(af)\n",
    "                    if dp > 100:\n",
    "    #                     reads_pos_dict[info] = {'alt':alt_count1,'ref':ref_count,'type':type2,'allele_frequency':af}\n",
    "                        if info not in dict_mut_num:\n",
    "                            dict_mut_num[info] = 1\n",
    "                        else:\n",
    "                            dict_mut_num[info] += 1\n",
    "    #         print(reads_pos_dict)\n",
    "\n",
    "\n",
    "\n",
    "    filtered_list = []# 测序深度>100且出现在至少2个样本中的突变。\n",
    "    for k,v in dict_mut_num.items():\n",
    "        if v > 1:\n",
    "            filtered_list.append(k)\n",
    "    # print(filtered_list)\n",
    "\n",
    "\n",
    "    #根据filtered_list筛选突变，输出csv。\n",
    "    for i in bayes_filenames:\n",
    "        if i.endswith('vcf'):\n",
    "            i_1 = i.split('.')[0]\n",
    "            reads_pos_dict = {}\n",
    "            path1 = prj_path +'/'+i\n",
    "            vcf_reader = vcf.Reader(filename=path1)\n",
    "            for record in vcf_reader:\n",
    "    #             print(record)\n",
    "    #             print(record.INFO)\n",
    "\n",
    "                alt_count = record.INFO['AO']\n",
    "                ref_count = record.INFO['RO']\n",
    "                ref = str(record).split(',')[2].split('=')[1]\n",
    "                type0 = record.INFO['TYPE']\n",
    "                position = str(record).split(',')[1].split('=')[1]\n",
    "                dp = record.INFO['DP']\n",
    "                if type0 not in type_list:\n",
    "                    type_list.append(type0)\n",
    "                for i in range(0,len(record.INFO['TYPE'])):\n",
    "                    alt1 = str(record).split('=')[4].replace(')','').replace('[','').replace(']','').replace(' ','')\n",
    "                    alt2 = alt1.split(\",\")#转成列表,碱基\n",
    "                    type2 = record.INFO['TYPE'][i]\n",
    "                    info = f'{ref}_{position}_{alt2[i]}'\n",
    "                    alt_count1 = alt_count[i]\n",
    "                    af = record.INFO['AO'][i]/(record.INFO['AO'][i] + record.INFO['RO'])    \n",
    "                    if dp > 100:#即使有列表了也还是需要测序深度>100的这个条件，不然有可能是出现在样本多但是测序深度不行的。\n",
    "                        if info in filtered_list:\n",
    "                            if type2 == 'snp' or type2 == 'del' or type2 == 'ins':#筛选变异类型\n",
    "                                reads_pos_dict[info] = {'alt':alt_count1,'ref':ref_count,'type':type2,'allele_frequency':af,'sample_exist':dict_mut_num[info]}\n",
    "    #         print(reads_pos_dict)\n",
    "\n",
    "            with open(f'/mnt/alamo01/users/yangjingqi/RSV_sra/group/10change_lofreq/01filtered_csv_deep_sample/{p}/{i_1}.csv','w') as f:#表格可以加个频率\n",
    "                writer = csv.writer(f)\n",
    "                writer.writerow([\"mutation\",\"alt_reads\",\"ref_reads\",\"type\",\"app\",\"allele_frequency\",\"sample_exist'\"])\n",
    "                for k,v in reads_pos_dict.items():\n",
    "                    writer.writerow([k,v['alt'],v['ref'],v['type'],'freebayes',v['allele_frequency'],v['sample_exist']])\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91baac6d-1177-4325-a455-42e3f1530e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vcf_all里面有乱七八糟的单端数据啥的，只要pair的，把metadata手动变成csv(用wps)，筛选出来这些vcf，移入vcf_pair,这个是分过组的。\n",
    "#/mnt/alamo01/users/yangjingqi/RSV_sra/group/09change_ref/00script/04vcf_all_to_pair/04vcf_all_to_pair.py\n",
    "import os\n",
    "import csv\n",
    "#新建分组的文件夹\n",
    "\n",
    "wenjianjia_list = os.listdir('/mnt/alamo01/users/yangjingqi/RSV_sra/yjq_sra_bioproject_rsv')\n",
    "for i in wenjianjia_list:\n",
    "    dirs = f'/mnt/alamo01/users/yangjingqi/RSV_sra/group/10change_lofreq/vcf_pair/{i}'\n",
    "    if not os.path.exists(dirs):\n",
    "        os.makedirs(dirs)\n",
    "        \n",
    "list_sra_pair=[]        \n",
    "with open('/mnt/alamo01/users/yangjingqi/RSV_sra/group/pair_metadata.csv') as csvfile:\n",
    "    csv_reader = csv.reader(csvfile)  \n",
    "    for row in csv_reader:\n",
    "        if row[0] != 'Run':\n",
    "            list_sra_pair.append(row[0])\n",
    "        \n",
    "for i in wenjianjia_list:\n",
    "    vcf_prj_path = f'/mnt/alamo01/users/yangjingqi/RSV_sra/group/10change_lofreq/vcf_result/{i}'\n",
    "    vcf_list = os.listdir(vcf_prj_path)\n",
    "    for n in vcf_list:\n",
    "        n1 = n.split('.')[0]\n",
    "        if n1 in list_sra_pair:\n",
    "            os.system(f'cp /mnt/alamo01/users/yangjingqi/RSV_sra/group/10change_lofreq/vcf_result/{i}/{n} /mnt/alamo01/users/yangjingqi/RSV_sra/group/10change_lofreq/vcf_pair/{i}/{n}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90715ff-980d-464c-85a4-8de2693e056f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
